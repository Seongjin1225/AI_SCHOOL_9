{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u6AUw_9iT-StDLE5IfpCEDnR401V3uPO",
      "authorship_tag": "ABX9TyPGYcNUhtK/18LOpQEu8znt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seongjin1225/AI_SCHOOL_9/blob/main/ML%26DL/12%EC%9B%94%2013%EC%9D%BC/12%EC%9B%94_13%EC%9D%BC_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 앙상블(Ensemble)\n",
        "- 여러 개의 모델 사용해 결론 도촐\n",
        "- Voting\n",
        "  -> hard voting : 서로 다른 모델 사용해서 다수결로 결정\n",
        "  -> soft voting : 서로 다른 모델 사용은 동일 but, 확률의 평균으로 결정\n",
        "- Bagging\n",
        "  -> 같은 모델 n개 사용하여 해결\n",
        "  -> 병렬\n",
        "- Boost\n",
        "  -> 모델로 평가 후 해당 모델 업그레이드 후 계속 진행\n",
        "  -> 순차적"
      ],
      "metadata": {
        "id": "1XdFhv4v_aBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블을 구현해 보아요\n",
        "# Voting을 iris를 가지고 구현\n",
        "# 모델은 knn, svm, decision tree 3개 사용\n",
        "\n",
        "# 필요 module import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "s7aqPbEDAx6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw Data Loading\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data,\n",
        "                  columns = iris.feature_names)\n",
        "df.columns = ['sepal_height','sepal_width','petal_height','petal_width']\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 결측치, 이상치는 없다고 가정\n",
        "# 중복 데이터 정리\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# 데이터셋 준비\n",
        "x_data = df.drop('target',axis=1,inplace=False).values\n",
        "t_data = df['target'].values\n",
        "\n",
        "# 정규화\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_data)\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "\n",
        "# 데이터 분리\n",
        "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
        "train_test_split(x_data_norm,\n",
        "                 t_data,\n",
        "                 stratify=t_data,\n",
        "                 test_size=0.3,\n",
        "                 random_state=0)"
      ],
      "metadata": {
        "id": "lI4n5R37B3O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN 구현\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "knn.fit(x_data_train_norm,\n",
        "        t_data_train)\n",
        "knn_acc = accuracy_score(t_data_test, knn.predict(x_data_test_norm))\n",
        "print(f'KNN 모델의 정확도 : {knn_acc}')\n",
        "\n",
        "# SVM 구현\n",
        "svm = SVC(kernel='linear',\n",
        "          C=0.5,\n",
        "          probability=True)\n",
        "\n",
        "svm.fit(x_data_train_norm,\n",
        "        t_data_train)\n",
        "svm_acc = accuracy_score(t_data_test, svm.predict(x_data_test_norm))\n",
        "print(f'SVM 모델의 정확도 : {svm_acc}')\n",
        "\n",
        "# DT 구현\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "dt.fit(x_data_train_norm,\n",
        "        t_data_train)\n",
        "dt_acc = accuracy_score(t_data_test, dt.predict(x_data_test_norm))\n",
        "print(f'DT 모델의 정확도 : {dt_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLcaL1BrCLoz",
        "outputId": "6d971963-c68e-4d0d-cd71-775f2ab32bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN 모델의 정확도 : 0.9777777777777777\n",
            "SVM 모델의 정확도 : 0.9777777777777777\n",
            "DT 모델의 정확도 : 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블 모델을 만들어요!\n",
        "# hard voting classifier(hvc)\n",
        "hvc = VotingClassifier(estimators=[('KNN',knn),\n",
        "                                   ('SVM',svm),\n",
        "                                   ('DT',dt)],\n",
        "                       voting='hard')\n",
        "\n",
        "hvc.fit(x_data_train_norm, t_data_train)\n",
        "hvc_acc = accuracy_score(t_data_test, hvc.predict(x_data_test_norm))\n",
        "print(f'앙상블 모델(hard voting)의 accuracy : {hvc_acc}')\n",
        "\n",
        "# soft voting classifier(svc)\n",
        "svc = VotingClassifier(estimators=[('KNN',knn),\n",
        "                                   ('SVM',svm),\n",
        "                                   ('DT',dt)],\n",
        "                       voting='soft')\n",
        "\n",
        "svc.fit(x_data_train_norm, t_data_train)\n",
        "svc_acc = accuracy_score(t_data_test, svc.predict(x_data_test_norm))\n",
        "print(f'앙상블 모델(soft voting)의 accuracy : {svc_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xan5i5hBDqWK",
        "outputId": "6dc1ba1a-904f-4211-ee81-0fb232cb5ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "앙상블 모델(hard voting)의 accuracy : 0.9777777777777777\n",
            "앙상블 모델(soft voting)의 accuracy : 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reset\n",
        "\n",
        "# 앙상블 Bagging을 구현해 보아요!\n",
        "# Decision Tree를 모아서 만든 Random Forest를 구현\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Raw Data Loading\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data,\n",
        "                  columns = iris.feature_names)\n",
        "df.columns = ['sepal_height','sepal_width','petal_height','petal_width']\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 결측치, 이상치는 없다고 가정\n",
        "# 중복 데이터 정리\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# 데이터셋 준비\n",
        "x_data = df.drop('target',axis=1,inplace=False).values\n",
        "t_data = df['target'].values\n",
        "\n",
        "# 정규화\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_data)\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "\n",
        "# 데이터 분리\n",
        "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
        "train_test_split(x_data_norm,\n",
        "                 t_data,\n",
        "                 stratify=t_data,\n",
        "                 test_size=0.3,\n",
        "                 random_state=0)\n",
        "\n",
        "# DT 구현\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "dt.fit(x_data_train_norm,\n",
        "        t_data_train)\n",
        "dt_acc = accuracy_score(t_data_test, dt.predict(x_data_test_norm))\n",
        "print(f'DT 모델의 정확도 : {dt_acc}')\n",
        "\n",
        "# Random Forest 구현\n",
        "# n_estimators = decision tree의 개수\n",
        "# max_depth = 트리의 높이 지정\n",
        "rcf = RandomForestClassifier(n_estimators=50,\n",
        "                             max_depth=3,\n",
        "                             random_state=20)\n",
        "\n",
        "rcf.fit(x_data_train_norm, t_data_train)\n",
        "rcf_acc = accuracy_score(t_data_test, rcf.predict(x_data_test_norm))\n",
        "print(f'RandomForest 모델의 accuracy : {rcf_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUJfw-UwErPT",
        "outputId": "ad7c3eac-1c6a-4c2f-e0b9-18a47f620dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
            "DT 모델의 정확도 : 0.9555555555555556\n",
            "RandomForest 모델의 accuracy : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블 boost\n",
        "%reset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "# Raw Data Loading\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data,\n",
        "                  columns = iris.feature_names)\n",
        "df.columns = ['sepal_height','sepal_width','petal_height','petal_width']\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 결측치, 이상치는 없다고 가정\n",
        "# 중복 데이터 정리\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# 데이터셋 준비\n",
        "x_data = df.drop('target',axis=1,inplace=False).values\n",
        "t_data = df['target'].values\n",
        "\n",
        "# 정규화\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_data)\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "\n",
        "# 데이터 분리\n",
        "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
        "train_test_split(x_data_norm,\n",
        "                 t_data,\n",
        "                 stratify=t_data,\n",
        "                 test_size=0.3,\n",
        "                 random_state=0)\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=50,\n",
        "                    max_depth=3,\n",
        "                    random_state=20)\n",
        "xgb.fit(x_data_train_norm, t_data_train)\n",
        "xgb_acc = accuracy_score(t_data_test, xgb.predict(x_data_test_norm))\n",
        "print(f'XGB 모델의 정확도 : {xgb_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7GdWkEHH43_",
        "outputId": "2e8ddfb0-141c-455f-ff16-1a05300d7d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
            "XGB 모델의 정확도 : 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최초의 neural network => Perceptron\n",
        "# 아주 간단하게 생각하면 logistic regression과 같아요!\n",
        "# 대신에 activation 함수를 logistic은 sigmoid를 이용해요\n",
        "# 하지만 Perceptron은 activation함수로 step function을 사용해요!\n",
        "\n",
        "# 이런 Perceptron은 각종 GATE연산을 학습할 수 있으면\n",
        "# 이를 이용해서 AI를 만들 수 있겠다라고 당시에 생각했어요!\n",
        "# 여기서 말하는 GATE연산은(AND, OR, NOR, XOR, ...)\n",
        "\n",
        "# 우리도 Perceptron이 GATE연산을 학습할 수 있는지 확인하기 위해\n",
        "# Logistic Regression을 이용해서 GATE연산을 학습해 볼꺼예요!\n",
        "\n",
        "# Tensorflow Keras로 구현해 보아요!\n",
        "# AND, OR, XOR 연산만 해 보아요!\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Training Data Set\n",
        "x_data = np.array([[0,0],\n",
        "                   [0,1],\n",
        "                   [1,0],\n",
        "                   [1,1]], dtype=np.float32)\n",
        "\n",
        "#  AND 연산\n",
        "# t_data = np.array([[0],[0],[0],[1]], dtype=np.float32)\n",
        "\n",
        "# OR 연산\n",
        "t_data = np.array([[0],[1],[1],[1]],dtype=np.float32)\n",
        "\n",
        "# XOR\n",
        "# t_data = np.array([[0],[1],[1],[0]],dtype=np.float32)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=(2,)))\n",
        "model.add(Dense(units=1,\n",
        "                activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-2),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit(x_data,\n",
        "          t_data,\n",
        "          epochs=10000,\n",
        "          verbose=0)\n",
        "\n",
        "print(f'정확도는 : {model.evaluate(x_data,t_data)}')\n",
        "# 정확도는 : [0.0003106207004748285, 1.0]\n",
        "\n",
        "# 정확도는 : [0.0003516915312502533, 1.0] => AND 연산에 대한 학습 결과\n",
        "# 정확도는 : [0.00015051690570544451, 1.0] => OR 연산에 대한 학습 결과\n",
        "# 정확도는 : 정확도는 : [1.5216578219678922e-08, 1.0] => XOR 연산에 대한 학습 결"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nxk5Pm9OcN7",
        "outputId": "2917446a-a875-4f7c-bad1-621708383e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 116ms/step - loss: 9.8468e-05 - acc: 1.0000\n",
            "정확도는 : [9.846834291238338e-05, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이번에는 다중 layer perceptron을 이용해서 GATE연산을 학습해 볼꺼예요!\n",
        "\n",
        "# Tensorflow Keras로 구현해 보아요!\n",
        "# AND, OR, XOR 연산만 해 보아요!\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Training Data Set\n",
        "x_data = np.array([[0,0],\n",
        "                   [0,1],\n",
        "                   [1,0],\n",
        "                   [1,1]], dtype=np.float32)\n",
        "\n",
        "# AND 연산\n",
        "t_data = np.array([[0],[0],[0],[1]], dtype=np.float32)\n",
        "\n",
        "# OR 연산\n",
        "# t_data = np.array([[0],[1],[1],[1]],dtype=np.float32)\n",
        "\n",
        "# XOR\n",
        "# t_data = np.array([[0],[1],[1],[0]],dtype=np.float32)\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Flatten(input_shape=(2,)))\n",
        "\n",
        "# 여러개의 Hidden Layer\n",
        "# Hidden Layer는 Dense layer를 사용해요!\n",
        "# Hidden Layer의 units => hyperparameter\n",
        "model.add(Dense(units=10,\n",
        "                activation='relu'))\n",
        "model.add(Dense(units=6,\n",
        "                activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=1,\n",
        "                activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-2),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit(x_data,\n",
        "          t_data,\n",
        "          epochs=30000,\n",
        "          verbose=0)\n",
        "\n",
        "print(f'정확도는 : {model.evaluate(x_data,t_data)}')"
      ],
      "metadata": {
        "id": "bMARmVFeXDY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b75f40-153b-425d-987d-5dfff6df6591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 167ms/step - loss: 6.2425e-09 - acc: 1.0000\n",
            "정확도는 : [6.242514061227666e-09, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존에 실습했던 MNIST 데이터 셋을\n",
        "# 두가지로 구현해볼 예정이에요\n",
        "\n",
        "# 1. Logistic Regression을 이용해서 Multinomial Classification\n",
        "# 2. DNN으로 Multinomial Classification 구현을 해 볼꺼예요!\n",
        "\n",
        "%reset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9tv9xIABN3d",
        "outputId": "ee9201fa-bae5-496c-bbd3-d06829cbb8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw Data Loading\n",
        "df = pd.read_csv('/content/drive/MyDrive/AI스쿨 파일/ML/MNIST/train.csv')\n",
        "df\n",
        "\n",
        "# 데이터셋 준비\n",
        "x_data = df.drop('label',axis=1,inplace=False).values\n",
        "t_data = df['label'].values\n",
        "\n",
        "# 정규화 진행\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_data)\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "\n",
        "# 데이터셋 분리\n",
        "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
        "train_test_split(x_data_norm,\n",
        "                 t_data,\n",
        "                 stratify=t_data,\n",
        "                 test_size=0.3,\n",
        "                 random_state=0)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Flatten(input_shape=(784,)))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(units=10,\n",
        "                activation='softmax'))\n",
        "\n",
        "# 설정\n",
        "model.compile(optimizer=Adam(learning_rate=1e-2),\n",
        "              loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# 학습\n",
        "history = model.fit(x_data_train_norm,\n",
        "                    t_data_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=100,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "\n",
        "# 평가\n",
        "print(model.evaluate(x_data_test_norm, t_data_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk5EbtjEDYLx",
        "outputId": "20bfe6a4-dea0-47b8-d710-0834ebfc98a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.2971\n",
            "Epoch 2/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2944 - val_loss: 0.3009\n",
            "Epoch 3/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2743 - val_loss: 0.2882\n",
            "Epoch 4/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2650 - val_loss: 0.2902\n",
            "Epoch 5/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2540 - val_loss: 0.2946\n",
            "Epoch 6/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2497 - val_loss: 0.2964\n",
            "Epoch 7/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2437 - val_loss: 0.2945\n",
            "Epoch 8/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2388 - val_loss: 0.3173\n",
            "Epoch 9/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2335 - val_loss: 0.3137\n",
            "Epoch 10/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2301 - val_loss: 0.3120\n",
            "Epoch 11/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2250 - val_loss: 0.3149\n",
            "Epoch 12/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.2262 - val_loss: 0.3173\n",
            "Epoch 13/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.2183 - val_loss: 0.3181\n",
            "Epoch 14/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.2181 - val_loss: 0.3307\n",
            "Epoch 15/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.2204 - val_loss: 0.3709\n",
            "Epoch 16/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.2173 - val_loss: 0.3426\n",
            "Epoch 17/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.2152 - val_loss: 0.3339\n",
            "Epoch 18/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2099 - val_loss: 0.3319\n",
            "Epoch 19/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2060 - val_loss: 0.3258\n",
            "Epoch 20/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2081 - val_loss: 0.3790\n",
            "Epoch 21/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2098 - val_loss: 0.3457\n",
            "Epoch 22/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2051 - val_loss: 0.3660\n",
            "Epoch 23/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2037 - val_loss: 0.3460\n",
            "Epoch 24/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2017 - val_loss: 0.3440\n",
            "Epoch 25/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2014 - val_loss: 0.3480\n",
            "Epoch 26/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.2023 - val_loss: 0.3521\n",
            "Epoch 27/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1962 - val_loss: 0.3599\n",
            "Epoch 28/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1965 - val_loss: 0.3442\n",
            "Epoch 29/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1924 - val_loss: 0.3518\n",
            "Epoch 30/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1957 - val_loss: 0.3682\n",
            "Epoch 31/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1933 - val_loss: 0.3601\n",
            "Epoch 32/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1926 - val_loss: 0.3822\n",
            "Epoch 33/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1936 - val_loss: 0.3715\n",
            "Epoch 34/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1885 - val_loss: 0.3860\n",
            "Epoch 35/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.1919 - val_loss: 0.3729\n",
            "Epoch 36/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.1893 - val_loss: 0.3745\n",
            "Epoch 37/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1871 - val_loss: 0.3758\n",
            "Epoch 38/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1900 - val_loss: 0.3985\n",
            "Epoch 39/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1919 - val_loss: 0.3844\n",
            "Epoch 40/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1870 - val_loss: 0.3786\n",
            "Epoch 41/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1842 - val_loss: 0.3903\n",
            "Epoch 42/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1821 - val_loss: 0.3821\n",
            "Epoch 43/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1855 - val_loss: 0.3754\n",
            "Epoch 44/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1807 - val_loss: 0.3914\n",
            "Epoch 45/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1827 - val_loss: 0.3866\n",
            "Epoch 46/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1860 - val_loss: 0.3968\n",
            "Epoch 47/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1810 - val_loss: 0.3926\n",
            "Epoch 48/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1809 - val_loss: 0.4116\n",
            "Epoch 49/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1841 - val_loss: 0.3875\n",
            "Epoch 50/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1774 - val_loss: 0.4014\n",
            "Epoch 51/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1768 - val_loss: 0.3995\n",
            "Epoch 52/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1799 - val_loss: 0.3952\n",
            "Epoch 53/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1805 - val_loss: 0.4292\n",
            "Epoch 54/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1789 - val_loss: 0.4042\n",
            "Epoch 55/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1790 - val_loss: 0.4089\n",
            "Epoch 56/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1748 - val_loss: 0.4158\n",
            "Epoch 57/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1743 - val_loss: 0.4181\n",
            "Epoch 58/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.1752 - val_loss: 0.4176\n",
            "Epoch 59/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1746 - val_loss: 0.4155\n",
            "Epoch 60/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1737 - val_loss: 0.4252\n",
            "Epoch 61/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1758 - val_loss: 0.4130\n",
            "Epoch 62/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1711 - val_loss: 0.4141\n",
            "Epoch 63/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1709 - val_loss: 0.4400\n",
            "Epoch 64/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1768 - val_loss: 0.4174\n",
            "Epoch 65/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1731 - val_loss: 0.4428\n",
            "Epoch 66/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1760 - val_loss: 0.4261\n",
            "Epoch 67/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1724 - val_loss: 0.4257\n",
            "Epoch 68/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1698 - val_loss: 0.4465\n",
            "Epoch 69/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1736 - val_loss: 0.4273\n",
            "Epoch 70/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1659 - val_loss: 0.4280\n",
            "Epoch 71/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1676 - val_loss: 0.4535\n",
            "Epoch 72/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1701 - val_loss: 0.4310\n",
            "Epoch 73/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1718 - val_loss: 0.4393\n",
            "Epoch 74/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1736 - val_loss: 0.4343\n",
            "Epoch 75/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1710 - val_loss: 0.4538\n",
            "Epoch 76/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1702 - val_loss: 0.4551\n",
            "Epoch 77/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1688 - val_loss: 0.4280\n",
            "Epoch 78/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1666 - val_loss: 0.4509\n",
            "Epoch 79/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1650 - val_loss: 0.4479\n",
            "Epoch 80/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1737 - val_loss: 0.4476\n",
            "Epoch 81/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1661 - val_loss: 0.4683\n",
            "Epoch 82/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1721 - val_loss: 0.4699\n",
            "Epoch 83/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1659 - val_loss: 0.4538\n",
            "Epoch 84/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1661 - val_loss: 0.4556\n",
            "Epoch 85/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1677 - val_loss: 0.4496\n",
            "Epoch 86/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1675 - val_loss: 0.4443\n",
            "Epoch 87/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1667 - val_loss: 0.4548\n",
            "Epoch 88/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1628 - val_loss: 0.4768\n",
            "Epoch 89/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1655 - val_loss: 0.4592\n",
            "Epoch 90/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1635 - val_loss: 0.4852\n",
            "Epoch 91/100\n",
            "236/236 [==============================] - 1s 3ms/step - loss: 0.1642 - val_loss: 0.4696\n",
            "Epoch 92/100\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 0.1623 - val_loss: 0.4591\n",
            "Epoch 93/100\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 0.1614 - val_loss: 0.4743\n",
            "Epoch 94/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1613 - val_loss: 0.4855\n",
            "Epoch 95/100\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.1636 - val_loss: 0.4629\n",
            "Epoch 96/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.1638 - val_loss: 0.4851\n",
            "Epoch 97/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.1623 - val_loss: 0.4795\n",
            "Epoch 98/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.1665 - val_loss: 0.4877\n",
            "Epoch 99/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.1646 - val_loss: 0.4848\n",
            "Epoch 100/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.1614 - val_loss: 0.4641\n",
            "394/394 [==============================] - 1s 3ms/step - loss: 0.5129\n",
            "0.5129320025444031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "predict = tf.argmax(model.predict(x_data_test_norm),axis=1).numpy()\n",
        "print(classification_report(t_data_test, predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSjZanKmDnMd",
        "outputId": "08edb029-eaeb-48a5-c907-aaa8894067f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "394/394 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95      1240\n",
            "           1       0.94      0.98      0.96      1405\n",
            "           2       0.91      0.85      0.88      1253\n",
            "           3       0.85      0.89      0.87      1305\n",
            "           4       0.90      0.93      0.91      1222\n",
            "           5       0.84      0.85      0.85      1139\n",
            "           6       0.92      0.95      0.93      1241\n",
            "           7       0.92      0.91      0.92      1320\n",
            "           8       0.88      0.85      0.86      1219\n",
            "           9       0.87      0.89      0.88      1256\n",
            "\n",
            "    accuracy                           0.90     12600\n",
            "   macro avg       0.90      0.90      0.90     12600\n",
            "weighted avg       0.90      0.90      0.90     12600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST를 Deep Network로 구현해 보아요!\n",
        "# Raw Data Loading\n",
        "df = pd.read_csv('/content/drive/MyDrive/AI스쿨 파일/ML/MNIST/train.csv')\n",
        "df\n",
        "\n",
        "# 데이터셋 준비\n",
        "x_data = df.drop('label',axis=1,inplace=False).values\n",
        "t_data = df['label'].values\n",
        "\n",
        "# 정규화 진행\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_data)\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "\n",
        "# 데이터셋 분리\n",
        "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
        "train_test_split(x_data_norm,\n",
        "                 t_data,\n",
        "                 stratify=t_data,\n",
        "                 test_size=0.3,\n",
        "                 random_state=0)\n",
        "\n",
        "# Model 구현(Regression Model 구현)\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Flatten(input_shape=(784,)))\n",
        "\n",
        "# Hidden Layer\n",
        "model.add(Dense(units=256,\n",
        "                activation='relu'))\n",
        "model.add(Dense(units=128,\n",
        "                activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=10,\n",
        "                activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-2),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "# model.summary()\n",
        "# 모델 학습\n",
        "history = model.fit(x_data_train_norm,\n",
        "                    t_data_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=100,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "# 모델 평가\n",
        "print(model.evaluate(x_data_test_norm,\n",
        "                     t_data_test))"
      ],
      "metadata": {
        "id": "LSUaVq9NGNtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 우리 model이 잘 만들어진 모델인지 확인!!!\n",
        "# 그래프를 이용해서 확인해보는게 좋아요!\n",
        "# 학습할때 학습데이터로 loss, acc를 구하고\n",
        "#          validation data로 val_loss, val_acc를 구하게 되는데\n",
        "# 이 둘간의 그래프를 비교해보면 overfitting의 정도를 확인!\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'],color='r')\n",
        "plt.plot(history.history['val_loss'],color='b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "60h8FDS2GeXd",
        "outputId": "116619d6-d200-4299-dcad-9c89c8952844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터를 Deep Network로 구현해 보아요!\n",
        "# Tensorflow Keras가 제공하는 여러 기능이 있는데\n",
        "# 그 중 필수적으로 사용하는 기능들이 있어요\n",
        "# 대표적인게 Early Stopping(조기종료) 기능이예요!\n",
        "\n",
        "# Raw Data Loading\n",
        "df = pd.read_csv('/content/drive/MyDrive/AI스쿨 파일/ML/MNIST/train.csv')\n",
        "df\n",
        "\n",
        "# 데이터셋 준비\n",
        "x_data = df.drop('label',axis=1,inplace=False).values\n",
        "t_data = df['label'].values\n",
        "\n",
        "# 정규화 진행\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_data)\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "\n",
        "# 데이터셋 분리\n",
        "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
        "train_test_split(x_data_norm,\n",
        "                 t_data,\n",
        "                 stratify=t_data,\n",
        "                 test_size=0.3,\n",
        "                 random_state=0)\n",
        "\n",
        "# Model 구현(Regression Model 구현)\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Flatten(input_shape=(784,)))\n",
        "\n",
        "# Hidden Layer\n",
        "model.add(Dense(units=256,\n",
        "                activation='relu'))\n",
        "model.add(Dense(units=128,\n",
        "                activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=10,\n",
        "                activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-2),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "# Early Stopping Callback 설정\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# monitor : 조기 종료의 기준\n",
        "# patience : loss값이 증가하는걸 몇번참을것인가에 대한 숫자.\n",
        "# patience는 모델이 정상적으로 돌아오면 다시 초기화\n",
        "es_cb = EarlyStopping(monitor='val_loss',\n",
        "                      patience=5,\n",
        "                      restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(x_data_train_norm,\n",
        "                    t_data_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=100,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[es_cb],\n",
        "                    verbose=1)\n",
        "# 모델 평가\n",
        "print(model.evaluate(x_data_test_norm,\n",
        "                     t_data_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHu9tXKgHvPw",
        "outputId": "bad6f060-55d2-4ab0-9cfb-cac8e25fff14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "236/236 [==============================] - 4s 12ms/step - loss: 0.3004 - acc: 0.9070 - val_loss: 0.1630 - val_acc: 0.9491\n",
            "Epoch 2/100\n",
            "236/236 [==============================] - 2s 10ms/step - loss: 0.1469 - acc: 0.9545 - val_loss: 0.1294 - val_acc: 0.9621\n",
            "Epoch 3/100\n",
            "236/236 [==============================] - 3s 12ms/step - loss: 0.1124 - acc: 0.9674 - val_loss: 0.1752 - val_acc: 0.9498\n",
            "Epoch 4/100\n",
            "236/236 [==============================] - 3s 12ms/step - loss: 0.0979 - acc: 0.9704 - val_loss: 0.1663 - val_acc: 0.9527\n",
            "Epoch 5/100\n",
            "236/236 [==============================] - 3s 12ms/step - loss: 0.0893 - acc: 0.9739 - val_loss: 0.1565 - val_acc: 0.9575\n",
            "Epoch 6/100\n",
            "236/236 [==============================] - 3s 12ms/step - loss: 0.0792 - acc: 0.9770 - val_loss: 0.1750 - val_acc: 0.9573\n",
            "Epoch 7/100\n",
            "236/236 [==============================] - 3s 12ms/step - loss: 0.0772 - acc: 0.9762 - val_loss: 0.1662 - val_acc: 0.9660\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.1435 - acc: 0.9574\n",
            "[0.14347082376480103, 0.9573809504508972]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lz-s0d5II66d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}